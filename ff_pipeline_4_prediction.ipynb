{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "inputs are train.csv, prediction.csv, output_dir, target \n",
    "where target is one of the six outcomes: gpa|grit|materialHardship|eviction|layoff|jobTraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "* summary: regression and classification\n",
    "* input: bg, tr, pr\n",
    "* output: predictions for NA values in pr\n",
    "'''\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from theano import shared\n",
    "import theano.tensor as T\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import sys\n",
    "\n",
    "train = \"/tigress/BEE/projects/rufragfam/ai4all/data/train.csv\"\n",
    "prediction = \"/tigress/BEE/projects/rufragfam/ai4all/data/prediction.csv\"\n",
    "output_dir = \"/tigress/BEE/projects/rufragfam/ai4all/output\"\n",
    "\n",
    "# define outcomes\n",
    "disout = ['eviction','layoff','jobTraining']\n",
    "conout = ['gpa','grit','materialHardship']\n",
    "outcome = conout[0]\n",
    "allout = disout+conout\n",
    "\n",
    "# np.random.seed(int(1234)) # for reproducibility\n",
    "\n",
    "# read in data\n",
    "bg = pd.read_csv(output_dir+'/'+outcome+'_fselected_bg.csv',index_col=0)\n",
    "\n",
    "nb_samples = bg.shape[0]\n",
    "\n",
    "tr = pd.read_csv(train, low_memory=False)\n",
    "tr = tr.set_index('challengeID')\n",
    "    \n",
    "pr = pd.read_csv(prediction, low_memory=False)\n",
    "pr = pr.set_index('challengeID')\n",
    "\n",
    "# by default we set all values in the prediction set to a number we wont see (-999)\n",
    "pr[:]=-999\n",
    "# then we add in the training samples\n",
    "pr.update(tr)\n",
    "#pr=pr.head(100)\n",
    "#bg=bg.head(100)\n",
    "tout = np.asarray(pr[outcome])\n",
    "\n",
    "print \"updated the predicted data frame with training samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "* Input: prefixes and prefix to wave/person mappings\n",
    "* Output: var_to_cols mapping of variable base to columns; \n",
    "* all variable roots are stored in the set var_roots\n",
    "* you can reconstruct information about a variable with splitVar(colval) \n",
    "*         which returns a tuple (is constructed?,prefix,variable base, wave)\n",
    "* to retrieve all variables associated with variable base varbase bg[var_to_cols[varbase]]\n",
    "'''\n",
    "\n",
    "# figure out which covariates are normally distributed and which are bernoulli\n",
    "norm_cols=[]\n",
    "bi_cols=[]\n",
    "norm_cols_idx=[]\n",
    "bi_cols_idx=[]\n",
    "idx = 0\n",
    "for col_name in bg:\n",
    "    bg[col_name]\n",
    "    col=bg[col_name]\n",
    "    if col.min()>=0 and col.max()-col.min()<=1:\n",
    "        bi_cols.append(col_name)\n",
    "        bi_cols_idx.append(idx)\n",
    "    else:\n",
    "        norm_cols.append(col_name)\n",
    "        norm_cols_idx.append(idx)\n",
    "    idx+=1\n",
    "\n",
    "# set up mapping from variable stem, to (variable ids, wave no.)\n",
    "all_prefix=[\"m1\",\"m2\",\"m3\",\"m4\",\"m5\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"hv3\",\"hv4\",\"hv5\",\"p5\",\"k5\",\n",
    "            \"ffcc\",\"kind\",\"t5\",\"emp3\",\"emp4\",\"emp5\",\"c3\",\"c4\",\"c5\",\"n5\",\"o5\",\"mf4\"]\n",
    "prefix_to_wave_personID = {\"m1\":(1,\"mother\"),\"m2\":(2,\"mother\"),\"m3\":(3,\"mother\"),\"m4\":(4,\"mother\"),\"m5\":(5,\"mother\"),\"f1\":(1,\"father\"),\n",
    "                           \"f2\":(2,\"father\"),\"f3\":(3,\"father\"),\"f4\":(4,\"father\"),\"f5\":(5,\"father\"),\"hv3\":(3,\"home_visit\"),\n",
    "                           \"hv4\":(4,\"home_visit\"),\"hv5\":(5,\"home_visit\"),\"p5\":(5,\"primary_caregiver\"),\"k5\":(5,\"child\"),\n",
    "                           \"ffcc\":(3,\"child_care_provider\"),\"kind\":(4,\"kindergarten_teacher\"),\"t5\":(5,\"teacher\"),\"emp3\":(3,\"emp\"),\n",
    "                           \"emp4\":(4,\"emp\"),\"emp5\":(5,\"emp\"),\"c3\":(3,\"c\"),\"c4\":(4,\"c\"),\"c5\":(4,\"c\"),\"n5\":(5,\"n\"),\"o5\":(5,\"o\"),\n",
    "                           \"mf4\":(4,'mother-father')}\n",
    "\n",
    "def splitVar(varname):\n",
    "    con_pre_varbase_wave = []\n",
    "    newcolval = varname\n",
    "    if varname[0]=='c':\n",
    "        con_pre_varbase_wave.append(True)\n",
    "        newcolval=varname[1:]\n",
    "    else:\n",
    "        con_pre_varbase_wave.append(False)\n",
    "    prefixes_for_this_col = []\n",
    "    varbase = newcolval\n",
    "    for prefix in all_prefix:\n",
    "        if newcolval.startswith(prefix):\n",
    "            prefixes_for_this_col.append(prefix)\n",
    "    if len(prefixes_for_this_col)==0:             \n",
    "        print \"could not find prefix for variable \" + str(newcolval)\n",
    "        con_pre_varbase_wave.append('')\n",
    "        con_pre_varbase_wave.append(varbase)\n",
    "    elif len(prefixes_for_this_col)>1:\n",
    "        print \"too many matching prefixes for variable \" + str(newcolval)\n",
    "        con_pre_varbase_wave.append('')\n",
    "        con_pre_varbase_wave.append(varbase)\n",
    "    else:\n",
    "        con_pre_varbase_wave.append(prefixes_for_this_col[0])\n",
    "        if con_pre_varbase_wave[0]:\n",
    "            varbase = varname[len('c'+prefixes_for_this_col[0]):]\n",
    "        else:\n",
    "            varbase = varname[len(prefixes_for_this_col[0]):]\n",
    "        con_pre_varbase_wave.append(varbase)\n",
    "    if con_pre_varbase_wave[1]!='':\n",
    "        con_pre_varbase_wave.append(prefix_to_wave_personID[con_pre_varbase_wave[1]][0])\n",
    "    else:\n",
    "        con_pre_varbase_wave.append('')\n",
    "    return con_pre_varbase_wave\n",
    "    \n",
    "# construct variable roots and a map to the variables across time\n",
    "# note that the termporal component is not currently used in the GLM\n",
    "var_to_cols = {}\n",
    "var_roots = set()\n",
    "for colval in bg:\n",
    "    con_pre_varbase_wave = splitVar(colval)\n",
    "    var = con_pre_varbase_wave[2]\n",
    "    if var not in var_to_cols:\n",
    "        var_to_cols[var]=[]\n",
    "    var_to_cols[var].append(colval)\n",
    "    var_roots.add(splitVar(colval)[2])\n",
    "    \n",
    "print \"constructed variable to columns mapping across waves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic regularized regression\n",
    "# get training data for a response variable ('gpa', 'grit', 'materialHardship', \n",
    "# 'eviction', 'layoff', or 'jobTraining) in typical X, y format\n",
    "def get_training_data(response):\n",
    "    y = tr[response]\n",
    "    y = y[y.notnull()]\n",
    "\n",
    "    train_ids = y.index.tolist()\n",
    "    y = y.values\n",
    "\n",
    "    X = bg.ix[train_ids].as_matrix()\n",
    "    \n",
    "    return X, y, train_ids\n",
    "\n",
    "# get testing data for a response variable ('gpa', 'grit', 'materialHardship', \n",
    "# 'eviction', 'layoff', or 'jobTraining) -- only X\n",
    "def get_testing_data(response):\n",
    "    y = tr[response]\n",
    "    y = y[y.notnull()]\n",
    "\n",
    "    train_ids = y.index.tolist()\n",
    "    test_ids = [i for i in bg.index.tolist() if i not in train_ids]\n",
    "    test_ids = sorted(test_ids)\n",
    "    X = bg.ix[test_ids].as_matrix()\n",
    "    \n",
    "    return X, test_ids\n",
    "\n",
    "def split_data(X, y, split=0.1):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    indices = range(0, X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    pivot = int(X.shape[0] * split)\n",
    "    \n",
    "    major_indices = indices[pivot:]\n",
    "    minor_indices = indices[:pivot]\n",
    "    \n",
    "    X_major = X[major_indices, :]\n",
    "    X_minor = X[minor_indices, :]\n",
    "    y_major = y[major_indices]\n",
    "    y_minor = y[minor_indices]\n",
    "    \n",
    "    return (X_major, y_major), (X_minor, y_minor)\n",
    "    \n",
    "'''\n",
    "* summary: provides functions for performing lasso\n",
    "'''\n",
    "\n",
    "def predict(response, model_func, nb_trials):\n",
    "    is_binary = response in ['eviction', 'layoff', 'jobTraining']\n",
    "\n",
    "    X_train_all, y_train_all, train_ids = get_training_data(response)\n",
    "\n",
    "    scores = []\n",
    "    for i in range(nb_trials):\n",
    "        (X_train, y_train), (X_val, y_val) = \\\n",
    "            split_data(X_train_all, y_train_all, split=0.5)\n",
    "\n",
    "        # validation phase (estimate performance)\n",
    "        model = model_func()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        if is_binary:\n",
    "            y_preds = model.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            y_preds = model.predict(X_val)\n",
    "\n",
    "        if is_binary: \n",
    "            loss = np.mean((y_preds - y_val) ** 2) # brier\n",
    "        else:   \n",
    "            loss = np.mean((y_preds - y_val) ** 2) # mse\n",
    "        scores.append(loss)\n",
    "        \n",
    "        print('Trial {}/{} done'.format(i + 1, nb_trials))\n",
    "        \n",
    "    if is_binary:\n",
    "        print(\"{} for {} / avg Brier loss = {:.4}\"\n",
    "              .format(model_func.__name__, response, np.mean(scores)))\n",
    "    else:\n",
    "        print(\"{} for {} / avg mse = {:.4}\"\n",
    "            .format(model_func.__name__, response, np.mean(scores)))\n",
    "\n",
    "    # model serving phase (on actual test data)\n",
    "    model = model_func()\n",
    "    model.fit(X_train_all, y_train_all)\n",
    "\n",
    "    X_test, test_ids = get_testing_data(response)\n",
    "    \n",
    "    assert X_test.shape[0] + X_train_all.shape[0] == bg.shape[0]\n",
    "    assert X_test.shape[1] == X_train.shape[1]\n",
    "    \n",
    "    if is_binary:\n",
    "        y_preds = model.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        y_preds = model.predict(X_test)\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    train_dict = dict(zip(train_ids, y_train_all))\n",
    "    test_dict = dict(zip(test_ids, y_preds))\n",
    "    \n",
    "    assert len(train_dict) + len(test_dict) == nb_samples\n",
    "    \n",
    "    for i in range(1, nb_samples+1):\n",
    "        if i in train_dict:\n",
    "            out.append(train_dict[i])\n",
    "        else:\n",
    "            assert i in test_dict\n",
    "            out.append(test_dict[i])\n",
    "            \n",
    "    return out\n",
    "\n",
    "\n",
    "def lasso_predict(response, nb_trials=5):\n",
    "    from sklearn import linear_model\n",
    "    return predict(response, linear_model.Lasso, nb_trials=nb_trials)\n",
    "\n",
    "def logit_predict(response, nb_trials=5):\n",
    "    from sklearn import linear_model\n",
    "    return predict(response, linear_model.LogisticRegression, nb_trials=nb_trials)\n",
    "\n",
    "\n",
    "PRODUCTION = True\n",
    "\n",
    "if PRODUCTION:\n",
    "    pr['eviction'] = logit_predict('eviction', nb_trials=1)\n",
    "    pr['layoff'] = logit_predict('layoff', nb_trials=1)\n",
    "    pr['jobTraining'] = logit_predict('jobTraining', nb_trials=1)\n",
    "    pr['gpa'] = lasso_predict('gpa', nb_trials=1)\n",
    "    pr['grit'] = lasso_predict('grit', nb_trials=1)\n",
    "    pr['materialHardship'] = lasso_predict('materialHardship', nb_trials=1)\n",
    "else:\n",
    "    pr['eviction'] = logit_predict('eviction')\n",
    "    pr['layoff'] = logit_predict('layoff')\n",
    "    pr['jobTraining'] = logit_predict('jobTraining')\n",
    "    pr['gpa'] = lasso_predict('gpa')\n",
    "    pr['grit'] = lasso_predict('grit')\n",
    "    pr['materialHardship'] = lasso_predict('materialHardship')\n",
    "    \n",
    "print \"output recorded\"\n",
    "pr.to_csv(output_dir+'/regression_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
