{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select fewer important features. \n",
    "\n",
    "This step may be skipped depending on what you are using for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature selection on imputed data\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "train = \"../ai4all_data/train.csv\"\n",
    "prediction = \"../ai4all_data/prediction.csv\"\n",
    "output_dir = \"output\"\n",
    "\n",
    "# master skip vector, fill skip feature selection in order: correlation selection, \n",
    "#                               tree classifier/regression importance selection,\n",
    "#                               variance feature selection\n",
    "skip_vector=(False,False,False)\n",
    "\n",
    "# feature selection settings\n",
    "'''\n",
    "correlation selection\n",
    "if correlation p-value > p_val_threshold, remove column\n",
    "set p_val_threshold to 1 to retain all columns\n",
    "'''\n",
    "bg = pd.read_csv(output_dir+'/imputed_bg.csv',index_col=0)\n",
    "p_val_threshold = 0.05\n",
    "\n",
    "# tree classifier/regression importance selection\n",
    "'''\n",
    " * Input thold: remove all features that are less than this importance threshold\n",
    " *              by default, we will remove only features with 0 importance across\n",
    " *              all outcomes\n",
    " *       keep:  remove all but <keep> features (overwrites thold)\n",
    "'''\n",
    "thold = None \n",
    "keep = 100\n",
    "\n",
    "# Variance feature selection\n",
    "'''\n",
    "'''\n",
    "bi_var_p = 0.95\n",
    "bi_var_threshold = bi_var_p*(1-bi_var_p)\n",
    "normal_var_threshold = 0.005\n",
    "\n",
    "\n",
    "disout = ['eviction','layoff','jobTraining']\n",
    "conout = ['gpa','grit','materialHardship']\n",
    "allout = disout+conout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing eviction\n",
      "running correlation based feature selection\n",
      "3433/3433 features kept\n",
      "running tree classification/regression importance based feature selection\n",
      "100/3433 features kept\n",
      "running variance based feature selection (remove columns with small variance)\n",
      "99/100 features kept\n",
      "\n",
      "processing layoff\n",
      "running correlation based feature selection\n",
      "3433/3433 features kept\n",
      "running tree classification/regression importance based feature selection\n",
      "100/3433 features kept\n",
      "running variance based feature selection (remove columns with small variance)\n",
      "100/100 features kept\n",
      "\n",
      "processing jobTraining\n",
      "running correlation based feature selection\n",
      "3433/3433 features kept\n",
      "running tree classification/regression importance based feature selection\n",
      "100/3433 features kept\n",
      "running variance based feature selection (remove columns with small variance)\n",
      "100/100 features kept\n",
      "\n",
      "processing gpa\n",
      "running correlation based feature selection\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[0] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-72c91127b573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mci\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbi_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;31m#spea_p = st.spearmanr(bg[[ci]][mask].as_matrix().flatten(),pr[co][mask].as_matrix())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python27/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python27/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python27/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[0] not in index'"
     ]
    }
   ],
   "source": [
    "for outcome in allout:\n",
    "    print \"processing \" + str(outcome)\n",
    "\n",
    "    bg = pd.read_csv(output_dir+'/imputed_bg.csv',index_col=0)\n",
    "    tr = pd.read_csv(train, low_memory=False)\n",
    "    tr = tr.set_index('challengeID')\n",
    "    pr = pd.read_csv(prediction, low_memory=False)\n",
    "    pr = pr.set_index('challengeID')\n",
    "\n",
    "    pr[:]=np.nan\n",
    "    pr.update(tr)\n",
    "\n",
    "    nb_samples = bg.shape[0]\n",
    "\n",
    "    # figure out distribution for columns\n",
    "    norm_cols=[]\n",
    "    bi_cols=[]\n",
    "    for col_name in bg:\n",
    "        bg[col_name]\n",
    "        col=bg[col_name]\n",
    "        if col.min()>=0 and col.max()-col.min()<=1:\n",
    "            bi_cols.append(col_name)\n",
    "        else:\n",
    "            norm_cols.append(col_name)\n",
    "\n",
    "    # normalization of normal columns\n",
    "    #rbs_scale = preprocessing.RobustScaler().fit(bg[norm_cols])\n",
    "    #nrm_scale = preprocessing.Normalizer().fit(bg[norm_cols])\n",
    "    #std_scale = preprocessing.StandardScaler().fit(bg[norm_cols])\n",
    "    #norm_scale = preprocessing.Normalizer().fit(bg[norm_cols])\n",
    "    #df_std = norm_scale.transform(bg[norm_cols])\n",
    "\n",
    "    tm = np.mean(bg[norm_cols])\n",
    "    ts = np.std(bg[norm_cols])\n",
    "    normed = (bg[norm_cols]-tm).divide(ts)\n",
    "    bg.loc[:,norm_cols]=normed\n",
    "\n",
    "\n",
    "    if ~skip_vector[0]:\n",
    "        # correlation feature selection, only continuous vs continuous implemented now\n",
    "        # compute pairwise correlations\n",
    "        print(\"running correlation based feature selection\")\n",
    "        col_names_to_remove = []\n",
    "\n",
    "        if outcome not in disout: # dependent variable continuous\n",
    "            mask=~np.isnan(pr[outcome])\n",
    "            for ci in range(bg.shape[1]):\n",
    "                if bg[[ci]].columns[0] not in bi_cols:\n",
    "                    corr = st.pearsonr(bg[[ci]][mask].as_matrix().flatten(),pr[outcome][mask].as_matrix())\n",
    "                    #spea_p = st.spearmanr(bg[[ci]][mask].as_matrix().flatten(),pr[co][mask].as_matrix())\n",
    "                    if corr[1]>p_val_threshold:\n",
    "                        col_names_to_remove.append(bg[[ci]].columns[0])\n",
    "                    #else:\n",
    "                        #plt.scatter(bg[[ci]][mask].as_matrix().flatten(),pr[co][mask].as_matrix())\n",
    "                        #plt.savefig(str(co)+\"_\"+bg[[ci]].columns[0]+\".png\")        \n",
    "\n",
    "        print('{}/{} features kept'.format(bg.shape[1] - len(col_names_to_remove), \n",
    "                                           bg.shape[1]))\n",
    "        bg = bg.drop(col_names_to_remove, axis=1)\n",
    "    \n",
    "    if ~skip_vector[1]:\n",
    "        # tree classifier/regression importance selection\n",
    "        print(\"running tree classification/regression importance based feature selection\")\n",
    "        all_fi = np.zeros(bg.shape[1],dtype=np.float64)\n",
    "        X = bg.as_matrix()\n",
    "        y = pr[outcome].as_matrix()\n",
    "        mask=~np.isnan(y)\n",
    "        if outcome in conout:\n",
    "            clf = ExtraTreesRegressor()\n",
    "            #clf = RandomForestRegressor()\n",
    "            y_train = np.asarray(y[mask], dtype=\"float\")\n",
    "        else:\n",
    "            clf = ExtraTreesClassifier()\n",
    "            #clf = RandomForestClassifier()\n",
    "            y_train = np.asarray(y[mask], dtype=\"i4\")\n",
    "        X_train = np.asarray(X[mask,:])\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        all_fi+=clf.feature_importances_\n",
    "\n",
    "        bs=bg.shape\n",
    "        if keep==None:\n",
    "            if thold==None:\n",
    "                thold = np.unique(sorted(all_fi))[1]\n",
    "            mask = all_fi>=thold\n",
    "            #model = SelectFromModel(clf, prefit=True,threshold=)\n",
    "            #X_new = model.transform(X_train)\n",
    "            #X_new.shape \n",
    "            bg = bg.iloc[:,np.where(mask)[0]]\n",
    "        else:\n",
    "            if bg.shape[1]>keep:\n",
    "                mask = all_fi>=sorted(all_fi)[-1*keep]\n",
    "                bg = bg.iloc[:,np.where(mask)[0]]\n",
    "\n",
    "        print('{}/{} features kept'.format(bg.shape[1],bs[1]))\n",
    "\n",
    "    if ~skip_vector[2]:\n",
    "        # Variance feature selection\n",
    "        print(\"running variance based feature selection (remove columns with small variance)\")\n",
    "        col_names_to_remove = []\n",
    "        idx = 0\n",
    "        for col_name in bg:\n",
    "            to_remove = False\n",
    "            col = bg[col_name]\n",
    "\n",
    "            if col.max()-col.min()<=1:\n",
    "                # is binary\n",
    "                b_p = col.sum()/nb_samples\n",
    "                b_var = nb_samples*b_p*(1-b_p)\n",
    "                if b_var < bi_var_threshold:\n",
    "                    to_remove = True\n",
    "            else: # is continuous\n",
    "                mu, std = norm.fit(col)\n",
    "                if std*std < normal_var_threshold:\n",
    "                    to_remove = True\n",
    "\n",
    "            if to_remove:\n",
    "                col_names_to_remove.append(col_name)\n",
    "\n",
    "        print('{}/{} features kept\\n'.format(bg.shape[1] - len(col_names_to_remove), \n",
    "                                           bg.shape[1]))\n",
    "        bg = bg.drop(col_names_to_remove, axis=1)\n",
    "        \n",
    "    bg.to_csv(output_dir+'/' + outcome + '_fselected_bg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python27]",
   "language": "python",
   "name": "Python [python27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
