{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "One of the most important and common question concerning data analysis if there is a statistical relationship between a response variable $Y$ and explanatory variables $X_i$. An common, powerful framework to address this question is to employ regression analysis in order to model the relationship. There are various types of regression analysis. The type of the regression model depends on the type of the distribution of the response variable $Y$; if it is continuous we use a linear regression model; if it is not continuous and binary (i.e., 0 or 1) we use logistic regression; if it follows a Poisson or binomial/multinomial distribution we use log-linear analysis. By modeling we try to predict the outcome $Y$ based on values of a set of predictor variables $X_i$ and noise $\\epsilon$. These methods allow us to assess the effects that the predictors $X_i$ have in the outcome $Y$. \n",
    "\n",
    "We will cover three different types of regression:\n",
    "\n",
    "1) Linear Regression (Models the value of one continuous outcome Y given one continuous or discrete predictor X)\n",
    "\n",
    "$Y = c_0 + c_1 X + \\epsilon$\n",
    "\n",
    "2) Multiple Linear Regression (Models the value of one continuous outcome Y given multiple continuous, discrete, or categorical predictors Xi)\n",
    "\n",
    "$Y = c_0 + c_1 X_1 + c_2 X_2 + c_3 X_3 + \\dots + c_n X_n + \\epsilon$\n",
    "\n",
    "3) Logistic Regression (Models the probability of a binary outcome Y given one continuous or discrete predictor X)\n",
    "\n",
    "$ \\frac{p(Y)}{1-p(Y)} = c_0 + c_1 X + \\epsilon$\n",
    "\n",
    "4) Multiple Logistic Regression (Models the probability of a binary outcome Y given multiple continuous, discrete, or categorical predictors Xi)\n",
    "\n",
    "$\\frac{p(Y)}{1-p(Y)} = c_0 + c_1 X_1 + c_2 X_2 + c_3 X_3 + \\dots + c_n X_n + \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Linear regression is a linear approach to modelling the relationship between a continuous variable (called the outcome or the dependent variable) and one explanatory variable (called predictor or independent variable). \n",
    "\n",
    "In linear regression, we plot the data on a scatter plot and then compute the best-fit line through the data points. The term \"best-fit\" refers to the fact that the resulting line minimizes the squared distance between the data points and the line. \n",
    "\n",
    "The best-fit line is described by the equation:\n",
    "\n",
    "$Y = c_0 + c_1 X + \\epsilon$\n",
    "\n",
    "where $c_0$ is the regression coefficient associated with the value of $Y$ when $X=0$, $c_1$ is the regression coefficient that tells us by how much $Y$ changes when $X$ is not zero, and $\\epsilon$ is noise. For now, we will set $\\epsilon$ to zero, meaning we will ignore the effects of noise. The resulting equation $Y = c_0 + c_1 X$ is just the equation for a line with $c_0$ as its y-intercept and $c_1$ is its slope. \n",
    "\n",
    "The best-fit line provides what is known as a linear model which allows us to make predictions about the value of $Y$ given the value of $X$.\n",
    "\n",
    "In this section we will build a linear regression model to predict the child's GPA scores. As a predictor, we will use language and literacy skills (feature t5c13a), science and social skills (feature t5c13b), and math skills (feature t5c13c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we import the libraries we will use in this notebook and load the Fragile Families data. \n",
    "# The first line sets maplotlib plots to show inside the notebook.\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Directory with cleaned data\n",
    "background = \"../../ai4all_data/background.csv\"\n",
    "train = \"../../ai4all_data/train.csv\"\n",
    "output_dir = \"../output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data\n",
    "\n",
    "RENATO: I'm not sure what's going on in the next cell. It seems we are cleaning the data a little bit. Should we do that here? Better comments are needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-32b7a84b1120>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# ????\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'challengeID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Set index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdata_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'challengeID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_frame = pd.read_csv(background, low_memory=False)\n",
    "# Get number of samples in the data\n",
    "num_samples = data_frame.shape[0]\n",
    "# ????\n",
    "assert list(data_frame['challengeID'].to_dict().values()) == list(range(1, num_samples+1))\n",
    "# Set index\n",
    "data_frame = data_frame.set_index('challengeID')\n",
    "# Replace missing values with -3\n",
    "data_frame = data_frame.replace('missing', -3)\n",
    "# Transform all entries in data_frame to numeric (Is this necessary?)\n",
    "data_frame = data_frame.apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "# removing all non-numeric elements\n",
    "data_frame = data_frame.select_dtypes(include = [np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read outcome data\n",
    "outcome = pd.read_csv(train, low_memory=False)\n",
    "# set outcome data index to match data_frame index\n",
    "outcome = outcome.set_index('challengeID')\n",
    "# Remove null entries\n",
    "outcome = outcome.loc[~outcome['gpa'].isnull()]\n",
    "# How many samples do we have now?\n",
    "data_frame.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression for GPA using language and literacy skills ('t5c13a') as predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we select data_frame entries that match the entries in outcome\n",
    "data_frame = data_frame.loc[data_frame.index.isin(outcome.index.values)]\n",
    "# We extract the language and literacy skills from the data_frame\n",
    "lang_lit = data_frame.loc[~data_frame['t5c13a'].isnull()]\n",
    "lang_lit = lang_lit['t5c13a']\n",
    "# We extract GPA from the outcome data\n",
    "Y = outcome.loc[outcome.index.isin(lang_lit.index.values)]\n",
    "GPA = Y['gpa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scatter plots and histogram to see what the data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(lang_lit, GPA)\n",
    "plt.show()\n",
    "n, bins, patches = plt.hist(lang_lit,14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we calculate the average GPAs for students in each category(1,2,3,4,5) we might see the correlation between GPA and their literacy skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate average GPA for students whose language and literacy skills are far below average\n",
    "one = lang_lit.loc[lang_lit == 1 ]\n",
    "one_gpa = GPA.loc[GPA.index.isin(one.index.values)]\n",
    "one_gpa_mean = np.mean(one_gpa)\n",
    "# Calculate average GPA for students whose language and literacy skills are below average\n",
    "two = lang_lit.loc[lang_lit == 2]\n",
    "two_gpa = GPA.loc[GPA.index.isin(two.index.values)]\n",
    "two_gpa_mean = np.mean(two_gpa)\n",
    "# Calculate average GPA for students whose language and literacy skills are average\n",
    "three = lang_lit.loc[lang_lit == 3 ]\n",
    "three_gpa = GPA.loc[GPA.index.isin(three.index.values)]\n",
    "three_gpa_mean = np.mean(three_gpa)\n",
    "# Calculate average GPA for students whose language and literacy skills are above average\n",
    "four = lang_lit.loc[lang_lit == 4 ]\n",
    "four_gpa = GPA.loc[GPA.index.isin(four.index.values)]\n",
    "four_gpa_mean = np.mean(four_gpa)\n",
    "# Calculate average GPA for students whose language and literacy skills are far above average\n",
    "five = lang_lit.loc[lang_lit == 5 ]\n",
    "five_gpa = GPA.loc[GPA.index.isin(five.index.values)]\n",
    "five_gpa_mean = np.mean(five_gpa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the average GPA against language and literacy skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array([1,2,3,4,5])\n",
    "y_train = np.array([one_gpa_mean,two_gpa_mean,three_gpa_mean,four_gpa_mean,five_gpa_mean])\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's do linear regression with `numpy.polyfit`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef = np.polyfit(X_train,y_train,1)\n",
    "print('slope : {}'.format(coef[0]))\n",
    "print('intercept : {}'.format(coef[1]))\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.scatter(X_train, y_train)\n",
    "x = np.linspace(0, 6, 100)\n",
    "ax.plot(x, coef[0]*x + coef[1]);\n",
    "\n",
    "mse = np.mean(((coef[0]*X_train + coef[1] - y_train) ** 2))\n",
    "print('mean square error : {}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also do linear regression with `scipy.stats.linregress`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(X_train, y_train)\n",
    "\n",
    "print('slope : {}'.format(slope))\n",
    "print('intercept : {}'.format(intercept))\n",
    "print('r-squared : {}'.format(r_value**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do the same analysis for science and social skills ('t5c13b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "science_social = data_frame.loc[~data_frame['t5c13b'].isnull()]\n",
    "science_social = science_social['t5c13b']\n",
    "Y = outcome.loc[outcome.index.isin(science_social.index.values)]\n",
    "GPA = Y['gpa']\n",
    "plt.scatter(science_social, GPA)\n",
    "plt.show()\n",
    "n, bins, patches = plt.hist(science_social,14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate average GPA for students whose science and social skills are far below average\n",
    "one = science_social.loc[science_social == 1 ]\n",
    "one_gpa = GPA.loc[GPA.index.isin(one.index.values)]\n",
    "one_gpa_mean = np.mean(one_gpa)\n",
    "# Calculate average GPA for students whose science and social skills are below average\n",
    "two = science_social.loc[science_social == 2]\n",
    "two_gpa = GPA.loc[GPA.index.isin(two.index.values)]\n",
    "two_gpa_mean = np.mean(two_gpa)\n",
    "# Calculate average GPA for students whose science and social skills are average\n",
    "three = science_social.loc[science_social == 3 ]\n",
    "three_gpa = GPA.loc[GPA.index.isin(three.index.values)]\n",
    "three_gpa_mean = np.mean(three_gpa)\n",
    "# Calculate average GPA for students whose science and social skills are above average\n",
    "four = science_social.loc[science_social == 4 ]\n",
    "four_gpa = GPA.loc[GPA.index.isin(four.index.values)]\n",
    "four_gpa_mean = np.mean(four_gpa)\n",
    "# Calculate average GPA for students whose science and social skills are far above average\n",
    "five = science_social.loc[science_social == 5 ]\n",
    "five_gpa = GPA.loc[GPA.index.isin(five.index.values)]\n",
    "five_gpa_mean = np.mean(five_gpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter([1,2,3,4,5], [one_gpa_mean,two_gpa_mean,three_gpa_mean,four_gpa_mean,five_gpa_mean])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do the same analysis for math skills ('t5c13b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "math = data_frame.loc[~data_frame['t5c13c'].isnull()]\n",
    "math = math['t5c13c']\n",
    "Y = outcome.loc[outcome.index.isin(math.index.values)]\n",
    "GPA = Y['gpa']\n",
    "plt.scatter(math, GPA)\n",
    "plt.show()\n",
    "n, bins, patches = plt.hist(math,14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate average GPA for students whose math skills are far below average\n",
    "one = math.loc[math == 1 ]\n",
    "one_gpa = GPA.loc[GPA.index.isin(one.index.values)]\n",
    "one_gpa_mean = np.mean(one_gpa)\n",
    "# Calculate average GPA for students whose math skills are below average\n",
    "two = math.loc[math == 2]\n",
    "two_gpa = GPA.loc[GPA.index.isin(two.index.values)]\n",
    "two_gpa_mean = np.mean(two_gpa)\n",
    "# Calculate average GPA for students whose math skills are average\n",
    "three = math.loc[math == 3 ]\n",
    "three_gpa = GPA.loc[GPA.index.isin(three.index.values)]\n",
    "three_gpa_mean = np.mean(three_gpa)\n",
    "# Calculate average GPA for students whose math skills are above average\n",
    "four = math.loc[math == 4 ]\n",
    "four_gpa = GPA.loc[GPA.index.isin(four.index.values)]\n",
    "four_gpa_mean = np.mean(four_gpa)\n",
    "# Calculate average GPA for students whose math skills are far above average\n",
    "five = math.loc[math == 5 ]\n",
    "five_gpa = GPA.loc[GPA.index.isin(five.index.values)]\n",
    "five_gpa_mean = np.mean(five_gpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter([1,2,3,4,5], [one_gpa_mean,two_gpa_mean,three_gpa_mean,four_gpa_mean,five_gpa_mean])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "Multiple linear regression is a generalization of linear regression. In multiple linear regression we model the relationship between a continuous variable (called the outcome or the dependent variable) and multiple explanatory variables (called predictors or independent variables). \n",
    "\n",
    "As in linear regression, we plot the data on a scatter plot and then compute the best-fit line through the data points. However, we use a different equation for the best-fit line which takes into account the effects of multiple predictors $X_1,X_2,\\dots,X_n$: \n",
    "\n",
    "The best-fit line is described by the equation:\n",
    "\n",
    "$Y = c_0 + c_1 X_1 + c_2 X_2 + c_3 X_3 + \\dots + c_n X_n + \\epsilon$\n",
    "\n",
    "where $c_0$ is the regression coefficient associated with the value of $Y$ when $X=0$, and $c_i$ where $i = 1,2,3,\\dots,n$ is the regression coefficient that tells us by how much $Y$ changes when the predictor $X_i$ is not zero. As before, we will set $\\epsilon$ to zero, meaning we will ignore the effects of noise.\n",
    "\n",
    "The best-fit line provides what is known as a linear model which allows us to make predictions about the value of $Y$ given the values of $X_i$.\n",
    "\n",
    "In this section we will build a multiple linear regression model to predict the child's GPA scores. As predictors, we will use language and literacy skills (feature t5c13a), science and social skills (feature t5c13b), and math skills (feature t5c13c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Logistic regression models the relationship between a binary outcome $Y$ that can be either 1 or 0 and a predictor $X$. The main difference between logistic regression and linear and multiple linear regression is that the resulting model is not linear (it is not a line but a curve) and that it does not predict the value of the outcome $Y$ but instead it predicts the probability that $Y$ is equal to 1.\n",
    "\n",
    "As in linear regression, we plot the data on a scatter plot and then compute the best-fit curve through the data points using the following equation which takes into account that $Y$ is a binary variable,
    "\n",
    "$ \\frac{p(Y)}{1-p(Y)} = c_0 + c_1 X + \\epsilon$\n",
    "\n",
    "where $p(Y)$ is the probability that $Y=1, $$c_0$ is the regression coefficient associated with the probability that $Y=1$ when $X=0$, and $c_1$ is the regression coefficient that tells us how much the probability that $Y=1$ changes when the predictor $X$ is not zero. As before, we will set $\\epsilon$ to zero, meaning we will ignore the effects of noise.\n",
    "\n",
    "The best-fit curve provides a nonlinear model which allows us to make predictions about the probability that $Y=1$ or $Y=0$ given the values of $X$.\n",
    "\n",
    "In this section we will build a logistic regression model to predict eviction. For the predictor $X$ predictor, we will use SOMETHING(feature XXXXXXX)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
