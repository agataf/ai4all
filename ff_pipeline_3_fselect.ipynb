{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select fewer important features. \n",
    "\n",
    "This step may be skipped depending on what you are using for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File output/imputed_bg.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a40756b3884d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mset\u001b[0m \u001b[0mp_val_threshold\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0mto\u001b[0m \u001b[0mretain\u001b[0m \u001b[0mall\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m '''\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/imputed_bg.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mp_val_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python27/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python27/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python27/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python27/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python27/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File output/imputed_bg.csv does not exist"
     ]
    }
   ],
   "source": [
    "# feature selection on imputed data\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "train = \"data/train.csv\"\n",
    "prediction = \"data/prediction.csv\"\n",
    "output_dir = \"output\"\n",
    "\n",
    "# master skip vector, fill skip feature selection in order: correlation selection, \n",
    "#                               tree classifier/regression importance selection,\n",
    "#                               variance feature selection\n",
    "skip_vector=(False,False,False)\n",
    "\n",
    "# feature selection settings\n",
    "'''\n",
    "correlation selection\n",
    "if correlation p-value > p_val_threshold, remove column\n",
    "set p_val_threshold to 1 to retain all columns\n",
    "'''\n",
    "bg = pd.read_csv(output_dir+'/imputed_bg.csv',index_col=0)\n",
    "p_val_threshold = 0.05\n",
    "\n",
    "# tree classifier/regression importance selection\n",
    "'''\n",
    " * Input thold: remove all features that are less than this importance threshold\n",
    " *              by default, we will remove only features with 0 importance across\n",
    " *              all outcomes\n",
    " *       keep:  remove all but <keep> features (overwrites thold)\n",
    "'''\n",
    "thold = None \n",
    "keep = 100\n",
    "\n",
    "# Variance feature selection\n",
    "'''\n",
    "'''\n",
    "bi_var_p = 0.95\n",
    "bi_var_threshold = bi_var_p*(1-bi_var_p)\n",
    "normal_var_threshold = 0.005\n",
    "\n",
    "\n",
    "disout = ['eviction','layoff','jobTraining']\n",
    "conout = ['gpa','grit','materialHardship']\n",
    "allout = disout+conout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for outcome in allout:\n",
    "    print \"processing \" + str(outcome)\n",
    "\n",
    "    bg = pd.read_csv(output_dir+'/imputed_bg.csv',index_col=0)\n",
    "    tr = pd.read_csv(train, low_memory=False)\n",
    "    tr = tr.set_index('challengeID')\n",
    "    pr = pd.read_csv(prediction, low_memory=False)\n",
    "    pr = pr.set_index('challengeID')\n",
    "\n",
    "    pr[:]=np.nan\n",
    "    pr.update(tr)\n",
    "\n",
    "    nb_samples = bg.shape[0]\n",
    "\n",
    "    # figure out distribution for columns\n",
    "    norm_cols=[]\n",
    "    bi_cols=[]\n",
    "    for col_name in bg:\n",
    "        bg[col_name]\n",
    "        col=bg[col_name]\n",
    "        if col.min()>=0 and col.max()-col.min()<=1:\n",
    "            bi_cols.append(col_name)\n",
    "        else:\n",
    "            norm_cols.append(col_name)\n",
    "\n",
    "    # normalization of normal columns\n",
    "    #rbs_scale = preprocessing.RobustScaler().fit(bg[norm_cols])\n",
    "    #nrm_scale = preprocessing.Normalizer().fit(bg[norm_cols])\n",
    "    #std_scale = preprocessing.StandardScaler().fit(bg[norm_cols])\n",
    "    #norm_scale = preprocessing.Normalizer().fit(bg[norm_cols])\n",
    "    #df_std = norm_scale.transform(bg[norm_cols])\n",
    "\n",
    "    tm = np.mean(bg[norm_cols])\n",
    "    ts = np.std(bg[norm_cols])\n",
    "    normed = (bg[norm_cols]-tm).divide(ts)\n",
    "    bg.loc[:,norm_cols]=normed\n",
    "\n",
    "\n",
    "    if ~skip_vector[0]:\n",
    "        # correlation feature selection, only continuous vs continuous implemented now\n",
    "        # compute pairwise correlations\n",
    "        print(\"running correlation based feature selection\")\n",
    "        col_names_to_remove = []\n",
    "\n",
    "        if outcome not in disout: # dependent variable continuous\n",
    "            mask=~np.isnan(pr[outcome])\n",
    "            for ci in range(bg.shape[1]):\n",
    "                if bg[[ci]].columns[0] not in bi_cols:\n",
    "                    corr = st.pearsonr(bg[[ci]][mask].as_matrix().flatten(),pr[outcome][mask].as_matrix())\n",
    "                    #spea_p = st.spearmanr(bg[[ci]][mask].as_matrix().flatten(),pr[co][mask].as_matrix())\n",
    "                    if corr[1]>p_val_threshold:\n",
    "                        col_names_to_remove.append(bg[[ci]].columns[0])\n",
    "                    #else:\n",
    "                        #plt.scatter(bg[[ci]][mask].as_matrix().flatten(),pr[co][mask].as_matrix())\n",
    "                        #plt.savefig(str(co)+\"_\"+bg[[ci]].columns[0]+\".png\")        \n",
    "\n",
    "        print('{}/{} features kept'.format(bg.shape[1] - len(col_names_to_remove), \n",
    "                                           bg.shape[1]))\n",
    "        bg = bg.drop(col_names_to_remove, axis=1)\n",
    "    \n",
    "    if ~skip_vector[1]:\n",
    "        # tree classifier/regression importance selection\n",
    "        print(\"running tree classification/regression importance based feature selection\")\n",
    "        all_fi = np.zeros(bg.shape[1],dtype=np.float64)\n",
    "        X = bg.as_matrix()\n",
    "        y = pr[outcome].as_matrix()\n",
    "        mask=~np.isnan(y)\n",
    "        if outcome in conout:\n",
    "            clf = ExtraTreesRegressor()\n",
    "            #clf = RandomForestRegressor()\n",
    "            y_train = np.asarray(y[mask], dtype=\"float\")\n",
    "        else:\n",
    "            clf = ExtraTreesClassifier()\n",
    "            #clf = RandomForestClassifier()\n",
    "            y_train = np.asarray(y[mask], dtype=\"i4\")\n",
    "        X_train = np.asarray(X[mask,:])\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        all_fi+=clf.feature_importances_\n",
    "\n",
    "        bs=bg.shape\n",
    "        if keep==None:\n",
    "            if thold==None:\n",
    "                thold = np.unique(sorted(all_fi))[1]\n",
    "            mask = all_fi>=thold\n",
    "            #model = SelectFromModel(clf, prefit=True,threshold=)\n",
    "            #X_new = model.transform(X_train)\n",
    "            #X_new.shape \n",
    "            bg = bg.iloc[:,np.where(mask)[0]]\n",
    "        else:\n",
    "            if bg.shape[1]>keep:\n",
    "                mask = all_fi>=sorted(all_fi)[-1*keep]\n",
    "                bg = bg.iloc[:,np.where(mask)[0]]\n",
    "\n",
    "        print('{}/{} features kept'.format(bg.shape[1],bs[1]))\n",
    "\n",
    "    if ~skip_vector[2]:\n",
    "        # Variance feature selection\n",
    "        print(\"running variance based feature selection (remove columns with small variance)\")\n",
    "        col_names_to_remove = []\n",
    "        idx = 0\n",
    "        for col_name in bg:\n",
    "            to_remove = False\n",
    "            col = bg[col_name]\n",
    "\n",
    "            if col.max()-col.min()<=1:\n",
    "                # is binary\n",
    "                b_p = col.sum()/nb_samples\n",
    "                b_var = nb_samples*b_p*(1-b_p)\n",
    "                if b_var < bi_var_threshold:\n",
    "                    to_remove = True\n",
    "            else: # is continuous\n",
    "                mu, std = norm.fit(col)\n",
    "                if std*std < normal_var_threshold:\n",
    "                    to_remove = True\n",
    "\n",
    "            if to_remove:\n",
    "                col_names_to_remove.append(col_name)\n",
    "\n",
    "        print('{}/{} features kept\\n'.format(bg.shape[1] - len(col_names_to_remove), \n",
    "                                           bg.shape[1]))\n",
    "        bg = bg.drop(col_names_to_remove, axis=1)\n",
    "        \n",
    "    bg.to_csv(output_dir+'/' + outcome + '_fselected_bg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python27]",
   "language": "python",
   "name": "Python [python27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
